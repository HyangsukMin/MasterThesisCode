# from utils import *
# import numpy as np
# import tensorflow as tf
# from tensorflow.keras.layers import Dense, Conv1D, BatchNormalization, ReLU, Dropout, Flatten, Activation, AveragePooling1D, UpSampling1D, Conv1DTranspose
# 
# from sklearn.mixture import GaussianMixture
# from ticc.TICC_solver import TICC
# 
# def bs_ticc(data, w = 3, k = 6, l = 11e-2, b = 0, maxIters = 1):
#     if len(data.shape) > 2:
#         n_ts, w, d = data.shape
#         data = data.reshape((n_ts * w, d))
#     logging.info("Data shape: {}".format(data.shape))
#     ticc = TICC(window_size = w, number_of_clusters = k, lambda_parameter = l, beta = b, maxIters = maxIters, threshold = 2e-5,
#                 write_out_file = False, num_proc = 1)
#     (cluster_assignment, cluster_MRFs) = ticc.fit(data, delimiter = None)
#     return cluster_assignment, cluster_MRFs, ticc
# 
# def bs_gmm(data, k, covariance_type = "full"):
#     if len(data.shape) > 2:
#         n_ts, w, d = data.shape
#         data = data.reshape((n_ts, w * d))
#     logging.info("Data shape: {}".format(data.shape))
#     gmm = GaussianMixture(n_components = k, covariance_type = covariance_type)
#     gmm.fit(data)
#     labels = gmm.predict(data)
#     return labels, gmm
#    
# def NReLU(inputs):
#     m = tf.math.reduce_max(tf.keras.activations.relu(inputs), axis = -1, keepdims = True) + 1e-5
#     return tf.keras.activations.relu(inputs)/m
# 
# class TCN(tf.keras.Model):
#     def __init__(self, n_hidden, kernel_size = 3, num_filters = 32, num_dilation = 3, dropout_rate=0.5):
#         super(TCN, self).__init__()
#         self.num_dilation = num_dilation
#         self.num_filters = num_filters
#         self.tcn = []
#         self.tcn.append(Conv1D(filters=num_filters, kernel_size=1, strides=1, padding='same'))
#         for i in range(num_dilation):
#             dilated_conv = []
#             dilated_conv.append(Conv1D(filters = num_filters, kernel_size=kernel_size, strides=1, padding='same', dilation_rate = [2 ** i]))
#             dilated_conv.append(BatchNormalization())
#             dilated_conv.append(Activation(NReLU))
#             dilated_conv.append(Conv1D(filters = num_filters, kernel_size=1, strides=1, padding='same'))
#             dilated_conv.append(Dropout(rate=dropout_rate))
#             dilated_conv.append(AveragePooling1D(pool_size = 4, strides = 1, padding = 'same'))
#             self.tcn.append(dilated_conv)
#         self.tcn.append(Conv1D(filters=n_hidden, kernel_size=1, strides=1, padding='same', activation=None))
# 
#     def call(self, x, training = False):
#         for j in range(self.num_dilation + 2):
#             if 0 < j and j < self.num_dilation + 1:
#                 input = x
#                 for k in range(5):
#                     x = self.tcn[j][k](x, training=training)
#                 x = input + x
#             else:
#                 x = self.tcn[j](x, training=training)
#         return x
#     
# class CAE(tf.keras.Model):
#     def __init__(self, windows, n_latent, n_hidden, n_head = 8, num_filters = 8, kernel_size = 3, padding = 'causal', dilation_exp = 2, num_dilation = 3, dropout_rate = 0.25):
#         super(CAE, self).__init__()
#         self.results = {}
#         sampling_factor = windows // 16
#     
#         self.n_head = n_head
#         self.n_hidden = n_hidden
#         
#         self.temporal_encoder1 = TCN(n_hidden, kernel_size = kernel_size, num_filters = num_filters, num_dilation = num_dilation, dropout_rate = dropout_rate)
#         self.pattern_learning = Conv1D(filters = n_head * n_hidden, kernel_size = windows, padding = 'valid', groups = n_hidden)
#         
#         self.W = Dense(n_hidden)
#         
#         self.H = Conv1D(filters = n_hidden, kernel_size = 3, padding = 'same')
#         self.V = Dense(n_hidden, activation = "relu")
#         self.latent = Conv1D(n_latent, kernel_size = 3, padding = 'same')
#         
#         self.pool = AveragePooling1D(pool_size = sampling_factor, strides = None, padding='valid', data_format='channels_last')
#         self.upsample = UpSampling1D(size = sampling_factor)
#         
#         self.recon = TCN(n_hidden, kernel_size = kernel_size, num_filters = num_filters, num_dilation = num_dilation, dropout_rate = dropout_rate)
# 
#     def split_heads(self, x, batch_size):
#         '''
#         [batch_size, 1, n_head * n_hidden] -> [batch_size, h_head, 1, n_hidden]
#         '''
#         x = tf.reshape(x, (batch_size, -1, self.n_head, self.n_hidden))
#         return tf.transpose(x, perm=[0, 2, 1, 3])
#     
#     def encode(self, inputs, training = True):
#         n_bs, n_w, n_dim = inputs.shape
#         x = inputs
#         x = self.temporal_encoder1(x, training = training)
# 
#         self.results["x"] = x.numpy()
# 
#         P = self.pattern_learning(x, training = training)
#         P = self.split_heads(P, n_bs)
#         
#         W = self.W(P, training = training)
#         alpha = tf.nn.softmax(tf.reduce_mean(tf.einsum("ihxk,iwk->ihwx", W, x), axis = 1), axis = -1)
#         V = tf.reduce_sum(tf.einsum("iwx,iwk -> iwk", alpha, x), axis = 1)
#         H = self.H(x, training = training) + self.V(V, training = training)[:,None,:]
#         
#         # z = self.nrelu(self.latent(H, training = training))
#         self.results["H"] = H.numpy()
#         self.results["V"] = V.numpy()
#         self.results["alpha"] = alpha.numpy()
#         self.results["W"] = W.numpy()
#         self.results["P"] = P.numpy()
#         
#         z = tf.concat([x, H], axis = 0)
#         z = self.latent(H, training = training)
#         return z
#     
#     def call(self, inputs, training = True):
#         x = inputs
#         
#         z = self.encode(x, training = training)
#         
#         pool = self.pool(z)
#         upsample = self.upsample(pool)      
#         recon = self.recon(upsample, training = training)
#         
#         return z, recon
# 
# class ClassEstimation(tf.keras.Model):
#     def __init__(self, n_clusters):
#         super(ClassEstimation, self).__init__()
#         self.n_clusters = n_clusters
#         
#         self.dense1 = Dense(n_clusters*2, activation = "relu")
#         self.dense2 = Dense(n_clusters, activation = "softmax")
#     
#     def call(self, inputs, training = True):
#         y = self.dense1(inputs, training = training)
#         y = self.dense2(y, training = training)
#         return y
# 
# class Backbone(tf.keras.Model):
#     def __init__(self, windows, 
#                      n_clusters,
#                      n_latent, 
#                      n_hidden, 
#                      n_head = 8, 
#                      num_filters = 8, 
#                      kernel_size = 3, 
#                      padding = 'same', 
#                      dilation_exp = 2, 
#                      num_dilation = 3, 
#                      dropout_rate = 0.25
#                 ):
#         super(Backbone, self).__init__()
#         
#         self.cae = CAE(windows, n_latent, n_hidden, n_head , num_filters, kernel_size, padding, dilation_exp, num_dilation, dropout_rate)
#         self.ce = ClassEstimation(n_clusters)
#     
#     def get_latent(self, inputs, training = False):
#         z = self.cae.encode(inputs, training = training)
#         return z
#             
#     def call(self, inputs, training = True):
#         z, recon = self.cae(inputs, training = training)
#         pred = self.ce(z, training = training)
#         return z, recon, pred
#     
#     def predict(self, inputs, training = False):
#         x = inputs
#         z = self.cae.encode(x, training = training)
#         y = self.ce(z, training = training)
#         return tf.argmax(y, axis = -1)
#     
# class TTC:
#     def __init__(self, dataset, window, shift, n_latent, epochs, maxiters, beta, learning_rate, batch_size = 32):
#         
#         self.dataset = dataset
#         self.window = window
# 
#         data_X, data_y = load_dataset(dataset)
#         n_ts, n_dim = data_X.shape
#         n_clusters = len(np.unique(data_y))
#         
#         remainder = n_ts % n_clusters
#         
#         data_y_hat = np.repeat(np.arange(n_clusters), n_ts // n_clusters)
#         data_y_hat = np.concatenate([np.repeat(data_y_hat[0], remainder), data_y_hat])
#         
#         
#         optimizers = tf.keras.optimizers.Adam(learning_rate = learning_rate)        
#         self.backbone = Backbone(windows = window, n_clusters = n_clusters, n_latent = n_latent, n_hidden = n_dim)
#         #---------------------------------------#
#         # Train
#         #---------------------------------------# 
#         
#         loss_object_rec = tf.keras.losses.MeanSquaredError()
#         loss_object_clf = tf.keras.losses.SparseCategoricalCrossentropy()
#         
#         for epoch in range(1, epochs + 1):
#             train_X, train_y = create_assigning_dataset(inputs = data_X, labels = data_y_hat, window = window, shift = shift)
#             batch = create_batch(train_X, train_y, batch_size = batch_size, remaining = True)
#             total_loss_rec = 0
#             total_loss_clf = 0
# 
#             for iter, (data, label) in enumerate(batch):
#                 iter += 1
#                 with tf.GradientTape() as tape:
#                     z, recon, pred = self.backbone(data, training = True)
#                     loss_rec = loss_object_rec(data, recon)
#                     loss_clf = loss_object_clf(label, pred)
#                     loss = loss_rec + loss_clf * 0.1
#                 grads = tape.gradient(loss, self.backbone.trainable_weights)
#                 optimizers.apply_gradients(zip(grads, self.backbone.trainable_weights))
#                 
#                 total_loss_rec += loss_rec.numpy()
#                 total_loss_clf += loss_clf.numpy()
# 
#             if epoch == 1 or epoch % 4 == 0:
#                 test_X, test_y = create_assigning_dataset(inputs = data_X, labels = data_y, window = window, shift = window)
#                 z, recon, pred = self.backbone(test_X, training = False)
#                 z = z.numpy().reshape(-1, z.shape[-1])
#                 pred = np.argmax(pred.numpy(), -1).reshape(-1)
#                 remainder = n_ts % window
#                 z = np.concatenate([z[:-window], z[-remainder:]])
#                 pred = np.concatenate([pred[:-window], pred[-remainder:]])
#                 y_hat, _, _ = bs_ticc(z, data_y_hat, k = n_clusters, w = 1, b = beta, maxIters = maxiters)
#                 length = np.unique(y_hat, return_counts = True)
#                 print(length)
#                 print_metrics(test_y.reshape(-1), y_hat)
#                 print_metrics(test_y.reshape(-1), pred)
#                 data_y_hat = y_hat
#                 self.y_hat = y_hat            
#    
#     def predict(self):
#         data_X, data_y = load_dataset(self.dataset)
#         test_X, test_y = create_assigning_dataset(inputs = data_X, labels = data_y, window = self.window, shift = self.window)
#         return self.backbone.predict(test_X, training = False).numpy().reshape(-1)
#     
#     def get_latent(self):
#         data_X, data_y = load_dataset(self.dataset)
#         test_X, test_y = create_assigning_dataset(inputs = data_X, labels = data_y, window = self.window, shift = self.window)
#         return self.backbone.get_latent(test_X, training = False).numpy()
#



import numpy as np
import tensorflow as tf
from utils import *
from tensorflow.keras.layers import Dense, Conv1D, BatchNormalization, ReLU, Dropout, Flatten, Activation, AveragePooling1D, UpSampling1D, Conv1DTranspose
from tensorflow.keras import Model
from ticc.TICC_solver import TICC


def TICC:
    
def NReLU(inputs):
    m = tf.math.reduce_max(tf.keras.activations.relu(inputs), axis = -1, keepdims = True) + 1e-5
    return tf.keras.activations.relu(inputs)/m

class TCN(Model):
    def __init__(self, n_hidden, kernel_size = 3, num_filters = 32, num_dilation = 3, dropout_rate=0.5):
        super(TCN, self).__init__()
        self.num_dilation = num_dilation
        self.num_filters = num_filters
        self.tcn = []
        self.tcn.append(Conv1D(filters=num_filters, kernel_size=1, strides=1, padding='same'))
        for i in range(num_dilation):
            dilated_conv = []
            dilated_conv.append(Conv1D(filters = num_filters, kernel_size=kernel_size, strides=1, padding='same', dilation_rate = [2 ** i]))
            dilated_conv.append(BatchNormalization())
            dilated_conv.append(Activation(NReLU))
            dilated_conv.append(Conv1D(filters = num_filters, kernel_size=1, strides=1, padding='same'))
            dilated_conv.append(Dropout(rate=dropout_rate))
            dilated_conv.append(AveragePooling1D(pool_size = 4, strides = 1, padding = 'same'))
            self.tcn.append(dilated_conv)
        self.tcn.append(Conv1D(filters=n_hidden, kernel_size=1, strides=1, padding='same', activation=None))

    def call(self, x, training = False):
        for j in range(self.num_dilation + 2):
            if 0 < j and j < self.num_dilation + 1:
                input = x
                for k in range(5):
                    x = self.tcn[j][k](x, training=training)
                x = input + x
            else:
                x = self.tcn[j](x, training=training)
        return x

